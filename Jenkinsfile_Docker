pipeline {
    agent any

    environment {
        AWS_ACCOUNT_ID = '375299695019'
        AWS_DEFAULT_REGION = 'us-east-1'
        APP_SOURCE_PATH = 'pdf_converter_FastAPI_app/'
        TF_PATH = '.'
        APP_ZIP = "app_package.zip"
        LAYER_ZIP = "dependencies_layer.zip"
        S3_BUCKET = 'pdflambdabucket1575'
        EC2_AMI = "ami-0de716d6197524dd9" // Example Amazon Linux 2 AMI for us-east-1, verify latest
        EC2_KEY_PAIR = "efs_temp_key" // Must be a key pair in your AWS account
    }

    stages {
        stage('Initialize Variables') {
            steps {
                script {
                    env.hostUserId = sh(returnStdout: true, script: 'id -u').trim()
                    env.hostGroupId = sh(returnStdout: true, script: 'id -g').trim()
                    echo "Jenkins user/group ID: ${env.hostUserId}:${hostGroupId}"
                }
            }
        }

        stage('Build Lambda Packages') {
            agent {
                docker {
                    image 'public.ecr.aws/lambda/python:3.12'
                    args '--user 0 --entrypoint=""'
                }
            }
            steps {
                sh '''
                    set -x
                    # Install necessary tools
                    dnf update -y
                    dnf install -y zip unzip libffi-devel gcc postgresql-devel
                    
                    rm -f $APP_ZIP $LAYER_ZIP
                    rm -rf build
                    mkdir -p build/app build/dependencies/python
                    
                    # Copy application code
                    cp -r pdf_converter_FastAPI_app/main.py \\
                          pdf_converter_FastAPI_app/database.py \\
                          pdf_converter_FastAPI_app/models.py \\
                          pdf_converter_FastAPI_app/utils.py \\
                          pdf_converter_FastAPI_app/templates \\
                          build/app/
                    
                    # Zip the application code
                    echo "Zipping application code..."
                    cd build/app/
                    zip -r ../../$APP_ZIP .
                    cd ../../
                    
                    chmod +x pdf_converter_FastAPI_app/requirements.txt
                    echo "Installing dependencies from requirements.txt..."
                    # Use the pre-installed Python 3.9 interpreter
                    python3 -m pip install --no-cache-dir -r pdf_converter_FastAPI_app/requirements.txt -t build/dependencies/python/
                    
                    echo "Cleaning up unnecessary files..."
                    cd build/dependencies/python
                    
                    # More robust and aggressive cleanup commands, redirecting errors to /dev/null
                    find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
                    find . -type f -name "*.pyc" -delete 2>/dev/null
                    
                    # Cleanup of metadata and specific package components
                    rm -rf dist-info *.egg-info
                    rm -rf pydantic/v1 pydantic/deprecated
                    rm -rf passlib/_data dateutil/zoneinfo
                    rm -rf uvloop websockets watchfiles httptools
                    rm -rf jose/backends/native.py passlib/ext
                    
                    echo "Verifying contents of dependencies directory..."
                    ls -lR .
                    
                    # Navigate back to the root directory for zipping
                    cd ../../..
                    
                    # Zip the dependencies layer
                    echo "Zipping dependencies layer..."
                    cd build/dependencies/
                    zip -r ../../$LAYER_ZIP .
                    cd ../../
                    
                    echo "Checking for created zip files..."
                    ls -l $APP_ZIP $LAYER_ZIP
                    
                    echo "Checking sizes..."
                    # Check the size of the zipped files to ensure they are within Lambda limits
                    for file in $APP_ZIP $LAYER_ZIP; do
                        echo "Zipped size of $file: $(du -m $file | cut -f1) MB"
                        mkdir temp_unzip
                        unzip $file -d temp_unzip
                        UNZIPPED_SIZE_BYTES=$(find temp_unzip -type f -exec stat -c %s {} + | awk '{s+=$1} END {print s}')
                        UNZIPPED_SIZE_MB=$((UNZIPPED_SIZE_BYTES / 1024 / 1024))
                        echo "Unzipped size of $file: ${UNZIPPED_SIZE_MB} MB"
                        if (( UNZIPPED_SIZE_MB >= 70 )); then
                            echo "ERROR: Unzipped size of $file exceeds 70MB limit"
                            exit 1
                        fi
                        rm -rf temp_unzip
                    done
                '''
                sh 'chmod 777 "${APP_ZIP}" "${LAYER_ZIP}"'
                sh 'chown ${hostUserId}:${hostGroupId} $APP_ZIP $LAYER_ZIP'
                stash includes: "${APP_ZIP}", name: 'app-code'
                stash includes: "${LAYER_ZIP}", name: 'dependencies-layer'
            }
        }

        stage('Provision Base Infrastructure') {
            agent {
                docker {
                    image 'hashicorp/terraform:1.5.7'
                    args '--user 0 --entrypoint="" --dns 8.8.8.8'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        dir(env.TF_PATH) {
                            // --- ADD THESE LINES ---
                            unstash 'app-code'
                            unstash 'dependencies-layer'
                            // --- END OF ADDITION ---
                            
                            sh 'apk add --no-cache python3 py3-pip coreutils'
                            sh 'pip install awscli --no-cache-dir'

                            sh "aws s3 cp ${APP_ZIP} s3://${S3_BUCKET}/"
                            sh "aws s3 cp ${LAYER_ZIP} s3://${S3_BUCKET}/"
                            
                            def fileHashApp = sh(returnStdout: true, script: "sha256sum ${APP_ZIP} | awk '{print \$1}'").trim()
                            def fileHashLayer = sh(returnStdout: true, script: "sha256sum ${LAYER_ZIP} | awk '{print \$1}'").trim()

                            echo 'fileHashApp: ' + fileHashApp
                            echo 'fileHashLayer: ' + fileHashLayer

                            // sh '''
                            //     aws dynamodb create-table \
                            //         --table-name terraform-state-lock-table \
                            //         --attribute-definitions \
                            //         AttributeName=LockID,AttributeType=S \
                            //         --key-schema \
                            //         AttributeName=LockID,KeyType=HASH \
                            //         --provisioned-throughput \
                            //         ReadCapacityUnits=1,WriteCapacityUnits=1
                            // '''
                            // sh 'terraform init -migrate-state'
                            // sh 'terraform init -reconfigure'
                            sh 'terraform init -upgrade'
                            echo 'Deploying base infrastructure with Terraform...'
                            sh """
                                 terraform apply -auto-approve \
                                 -var 's3_key_app=${APP_ZIP}' \
                                 -var 'source_code_hash_app=${fileHashApp}' \
                                 -var 's3_key_layer=${LAYER_ZIP}' \
                                 -var 'source_code_hash_layer=${fileHashLayer}'
                             """
                            env.EFS_FILE_SYSTEM_ID = sh(returnStdout: true, script: 'terraform output -raw efs_file_system_id').trim()
                            env.EFS_ACCESS_POINT_ID = sh(returnStdout: true, script: 'terraform output -raw efs_access_point_id').trim()
                            env.EFS_SECURITY_GROUP_ID = sh(returnStdout: true, script: 'terraform output -raw app_security_group_id').trim()
                            env.PRIVATE_SUBNET_ID = sh(returnStdout: true, script: 'terraform output -json private_subnet_ids | python3 -c "import sys, json; print(json.load(sys.stdin)[0])"').trim()

                            echo "EFS File System ID: ${env.EFS_FILE_SYSTEM_ID}"
                            echo "EFS Access Point ID: ${env.EFS_ACCESS_POINT_ID}"
                            echo "EFS Security Group ID: ${env.EFS_SECURITY_GROUP_ID}"
                            echo "Private Subnet ID: ${env.PRIVATE_SUBNET_ID}"
                        }
                    }
                }
            }
        }

        stage('Populate EFS with LibreOffice') {
            agent {
                docker {
                    image 'amazon/aws-cli:2.11.16'
                    args '--user 0 --entrypoint=""'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
                        sshUserPrivateKey(credentialsId: 'ec2-ssh-key', keyFileVariable: 'SSH_KEY_FILE')
                    ]) {
                        sh 'yum update -y && yum install -y python3'
                        echo "Launching temporary EC2 instance. CloudWatch Logs will be sent to /aws/ec2/efs-populator-logs."
                        // echo "Running AWS CLI commands to create IAM role and instance profile for EFS population Only for one time..."
                        // sh """
                        // # Create the IAM role for the EC2 instance
                        // aws iam create-role --role-name efs-populator-role --assume-role-policy-document '{"Version":"2012-10-17","Statement":[{"Effect":"Allow","Principal":{"Service":"ec2.amazonaws.com"},"Action":"sts:AssumeRole"}]}'

                        // # Attach the CloudWatch agent policy to the new role
                        // aws iam attach-role-policy --role-name efs-populator-role --policy-arn arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy

                        // # Create the instance profile and associate it with the role
                        // aws iam create-instance-profile --instance-profile-name efs-populator-profile

                        // # Add the role to the instance profile
                        // aws iam add-role-to-instance-profile --instance-profile-name efs-populator-profile --role-name efs-populator-role
                        // """

                        def userDataScript = """
                            #!/bin/bash
                            set -ex
                            # The 'exec' command ensures all script output is captured.
                            exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1

                            # Install and configure the CloudWatch Agent
                            sudo yum install -y amazon-cloudwatch-agent
                            
                            sudo cat > /opt/aws/amazon-cloudwatch-agent/bin/config.json << EOF
                            {
                                "logs": {
                                    "logs_collected": {
                                        "files": {
                                            "collect_list": [
                                                {
                                                    "file_path": "/var/log/user-data.log",
                                                    "log_group_name": "/aws/ec2/efs-populator-logs",
                                                    "log_stream_name": "{instance_id}",
                                                    "timestamp_format": "%Y-%m-%dT%H:%M:%S%z"
                                                }
                                            ]
                                        }
                                    }
                                }
                            }
                            EOF
                            
                            sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json -s
                            
                            # Give the agent a moment to start
                            sleep 10
                            
                            echo "Starting EFS population script."
                            
                            sudo yum update -y
                            sudo yum install -y amazon-efs-utils
                            
                            echo "Waiting for EFS mount target..."
                            sleep 30
                            sudo mkdir -p /mnt/efs
                            sudo mount -t efs -o tls,accesspoint=${env.EFS_ACCESS_POINT_ID} ${env.EFS_FILE_SYSTEM_ID}.efs.${env.AWS_DEFAULT_REGION}.amazonaws.com:/ /mnt/efs
                            
                            # Download LibreOffice, install, and copy to EFS
                            wget "https://download.documentfoundation.org/libreoffice/stable/25.2.5/deb/x86_64/LibreOffice_25.2.5_Linux_x86-64_deb_sdk.tar.gz"
                            tar -zxvf LibreOffice_25.2.5_Linux_x86-64_deb_sdk.tar.gz
                            sudo yum install -y libreoffice
                            sudo cp -r /usr/lib64/libreoffice /mnt/efs/
                            
                            sudo umount /mnt/efs
                            
                            echo "EFS population complete. Terminating instance..."
                            aws ec2 terminate-instances --instance-ids \$(curl -s http://169.254.169.254/latest/meta-data/instance-id) --region ${env.AWS_DEFAULT_REGION}
                        """

                        // The rest of the stage remains the same
                        def run_instance_result = sh(
                            returnStdout: true,
                            script: """
                                aws ec2 run-instances \\
                                --region ${env.AWS_DEFAULT_REGION} \\
                                --image-id ${env.EC2_AMI} \\
                                --instance-type t2.micro \\
                                --key-name ${env.EC2_KEY_PAIR} \\
                                --security-group-ids ${env.EFS_SECURITY_GROUP_ID} \\
                                --subnet-id ${env.PRIVATE_SUBNET_ID} \\
                                --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=jenkins-efs-populator}]' \\
                                --iam-instance-profile Name=efs-populator-role \\
                                --user-data '${userDataScript}'
                            """
                        ).trim()
                        env.INSTANCE_ID = sh(returnStdout: true, script: "echo '${run_instance_result}' | python3 -c \"import sys, json; print(json.load(sys.stdin)['Instances'][0]['InstanceId'])\"").trim()
                        echo "Launched temporary EC2 instance ${env.INSTANCE_ID}. Check CloudWatch Logs for progress in the '/aws/ec2/efs-populator-logs' log group."
                    }
                }
            }
        }

        stage('Wait for EFS Population') {
            agent {
                docker {
                    image 'amazon/aws-cli:2.11.16'
                    args '--user 0 --entrypoint=""'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        echo "Waiting for EC2 instance ${env.INSTANCE_ID} to terminate..."
                        def instanceState = 'running'
                        def maxWaitTime = 1200 // 20 minutes in seconds
                        def pollInterval = 30 // 30 seconds
                        def elapsedTime = 0

                        while (instanceState != 'terminated' && elapsedTime < maxWaitTime) {
                            try {
                                def result = sh(
                                    returnStdout: true,
                                    script: "aws ec2 describe-instances --region ${env.AWS_DEFAULT_REGION} --instance-ids ${env.INSTANCE_ID} --query 'Reservations[0].Instances[0].State.Name' --output text"
                                ).trim()
                                
                                instanceState = result
                                echo "Current instance state: ${instanceState}"

                                if (instanceState != 'terminated') {
                                    echo "Instance is not terminated yet. Waiting ${pollInterval} seconds..."
                                    sleep(pollInterval)
                                    elapsedTime += pollInterval
                                }
                            } catch (error) {
                                // Handle potential "invalid instance ID" errors if instance terminates during polling
                                echo "Error while polling instance state: ${error}"
                                instanceState = 'terminated' // Exit the loop
                            }
                        }

                        if (instanceState == 'terminated') {
                            echo "EC2 instance ${env.INSTANCE_ID} has terminated. EFS population script completed successfully."
                        } else {
                            error "EC2 instance did not terminate within the maximum wait time of ${maxWaitTime} seconds."
                        }
                    }
                }
            }
        }

        stage('Deploy Remainder with Terraform') {
            agent {
                docker {
                    image 'hashicorp/terraform:1.5.7'
                    args '--user 0 --entrypoint="" --dns 8.8.8.8'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        unstash 'app-code'
                        unstash 'dependencies-layer'
                        
                        dir(env.TF_PATH) {
                            sh 'apk add --no-cache python3 py3-pip coreutils'
                            sh 'pip install awscli --no-cache-dir'

                            def fileHashApp = sh(returnStdout: true, script: "sha256sum ${APP_ZIP} | awk '{print \$1}'").trim()
                            def fileHashLayer = sh(returnStdout: true, script: "sha256sum ${LAYER_ZIP} | awk '{print \$1}'").trim()
                            
                            echo 'Deploying the remaining resources with Terraform...'
                            sh 'terraform init -upgrade'
                            sh """
                                terraform apply -auto-approve \
                                -var 's3_key_app=${APP_ZIP}' \
                                -var 'source_code_hash_app=${fileHashApp}' \
                                -var 's3_key_layer=${LAYER_ZIP}' \
                                -var 'source_code_hash_layer=${fileHashLayer}'
                            """
                        }
                    }
                }
            }
        }

        stage('Post-Deployment Info') {
            agent {
                docker {
                    image 'hashicorp/terraform:1.5.7'
                    args '--user 0 --entrypoint="" --dns 8.8.8.8'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        dir(env.TF_PATH) {
                            def apiGatewayUrl = sh(returnStdout: true, script: 'terraform output -raw api_gateway_url').trim()
                            echo "Deployment Complete! Your API Gateway URL: ${apiGatewayUrl}"
                        }
                    }
                }
            }
        }
    }

    post {
        always { echo 'Cleaning up...' }
        failure { echo 'Pipeline failed!' }
        success { echo 'Pipeline completed successfully!' }
    }
}
