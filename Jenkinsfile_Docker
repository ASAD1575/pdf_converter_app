pipeline {
    agent any

    environment {
        AWS_ACCOUNT_ID = '375299695019'
        AWS_DEFAULT_REGION = 'us-east-1'
        APP_SOURCE_PATH = 'pdf_converter_FastAPI_app/'
        TF_PATH = '.'
        APP_ZIP = "app_package.zip"
        LAYER_ZIP = "dependencies_layer.zip"
        S3_BUCKET = 'pdflambdabucket1575'
        EC2_AMI = "ami-0de716d6197524dd9" // Example Amazon Linux 2 AMI for us-east-1, verify latest
        EC2_KEY_PAIR = "efs_temp_key" // Must be a key pair in your AWS account
    }

    stages {
        stage('Initialize Variables') {
            steps {
                script {
                    env.hostUserId = sh(returnStdout: true, script: 'id -u').trim()
                    env.hostGroupId = sh(returnStdout: true, script: 'id -g').trim()
                    echo "Jenkins user/group ID: ${env.hostUserId}:${hostGroupId}"
                }
            }
        }

        stage('Build Lambda Packages') {
            agent {
                docker {
                    image 'public.ecr.aws/lambda/python:3.9'
                    args '--user 0 --entrypoint=""'
                }
            }
            steps {
                sh '''
                    set -x
                    # Install necessary tools
                    yum update -y
                    yum install -y zip unzip libffi-devel gcc postgresql-devel
                    
                    rm -f $APP_ZIP $LAYER_ZIP
                    rm -rf build
                    mkdir -p build/app build/dependencies/python
                    
                    # Copy application code
                    cp -r pdf_converter_FastAPI_app/main.py \\
                          pdf_converter_FastAPI_app/database.py \\
                          pdf_converter_FastAPI_app/models.py \\
                          pdf_converter_FastAPI_app/utils.py \\
                          pdf_converter_FastAPI_app/templates \\
                          build/app/
                    
                    # Zip the application code
                    echo "Zipping application code..."
                    zip -r $APP_ZIP build/app
                    
                    chmod +x pdf_converter_FastAPI_app/requirements.txt
                    echo "Installing dependencies from requirements.txt..."
                    # Use the pre-installed Python 3.9 interpreter
                    python3 -m pip install --no-cache-dir -r pdf_converter_FastAPI_app/requirements.txt -t build/dependencies/python/
                    
                    echo "Cleaning up unnecessary files..."
                    cd build/dependencies/python
                    
                    # More robust and aggressive cleanup commands, redirecting errors to /dev/null
                    find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null
                    find . -type f -name "*.pyc" -delete 2>/dev/null
                    find . -type d -name "tests" -exec rm -rf {} + 2>/dev/null
                    find . -type d -name "test" -exec rm -rf {} + 2>/dev/null
                    find . -type d -name "docs" -exec rm -rf {} + 2>/dev/null
                    find . -type d -name "examples" -exec rm -rf {} + 2>/dev/null
                    find . -type f -name "*.txt" -delete 2>/dev/null
                    find . -type f -name "*.md" -delete 2>/dev/null
                    find . -type f -name "*.rst" -delete 2>/dev/null
                    
                    # Cleanup of metadata and specific package components
                    rm -rf dist-info *.egg-info
                    rm -rf pydantic/v1 pydantic/deprecated
                    rm -rf passlib/_data dateutil/zoneinfo
                    rm -rf uvloop websockets watchfiles httptools
                    rm -rf jose/backends/native.py passlib/ext
                    
                    echo "Verifying contents of dependencies directory..."
                    ls -lR .
                    
                    # Navigate back to the root directory for zipping
                    cd ../../..
                    
                    # Zip the dependencies layer
                    echo "Zipping dependencies layer..."
                    zip -r $LAYER_ZIP build/dependencies
                    
                    echo "Checking for created zip files..."
                    ls -l $APP_ZIP $LAYER_ZIP
                    
                    echo "Checking sizes..."
                    # Check the size of the zipped files to ensure they are within Lambda limits
                    for file in $APP_ZIP $LAYER_ZIP; do
                        echo "Zipped size of $file: $(du -m $file | cut -f1) MB"
                        mkdir temp_unzip
                        unzip $file -d temp_unzip
                        UNZIPPED_SIZE_BYTES=$(find temp_unzip -type f -exec stat -c %s {} + | awk '{s+=$1} END {print s}')
                        UNZIPPED_SIZE_MB=$((UNZIPPED_SIZE_BYTES / 1024 / 1024))
                        echo "Unzipped size of $file: ${UNZIPPED_SIZE_MB} MB"
                        if (( UNZIPPED_SIZE_MB >= 70 )); then
                            echo "ERROR: Unzipped size of $file exceeds 70MB limit"
                            exit 1
                        fi
                        rm -rf temp_unzip
                    done
                '''
                stash includes: "${APP_ZIP}", name: 'app-code'
                stash includes: "${LAYER_ZIP}", name: 'dependencies-layer'
            }
        }

        stage('Provision Base Infrastructure') {
            agent {
                docker {
                    image 'hashicorp/terraform:1.5.7'
                    args '--user 0 --entrypoint="" --dns 8.8.8.8'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        unstash 'app-code'
                        unstash 'dependencies-layer'
                        
                        dir(env.TF_PATH) {
                        
                            sh 'apk add --no-cache python3 py3-pip coreutils'
                            sh 'pip install awscli --no-cache-dir'

                            sh "aws s3 cp ${APP_ZIP} s3://${S3_BUCKET}/"
                            sh "aws s3 cp ${LAYER_ZIP} s3://${S3_BUCKET}/"
                            
                            def fileHashApp = sh(returnStdout: true, script: "sha256sum ${APP_ZIP} | awk '{print \$1}'").trim()
                            def fileHashLayer = sh(returnStdout: true, script: "sha256sum ${LAYER_ZIP} | awk '{print \$1}'").trim()
                            
                            sh 'terraform init -upgrade'
                            echo 'Applying Terraform to create VPC, Security Group, and EFS...'
                            // A single, non-targeted apply for infrastructure is better
                            sh '''terraform apply -auto-approve \
                                -var 's3_key_app=${APP_ZIP}' \
                                -var 'source_code_hash_app=${fileHashApp}' \
                                -var 's3_key_layer=${LAYER_ZIP}' \
                                -var 'source_code_hash_layer=${fileHashLayer}'
                            '''
                            // After the apply completes, the outputs are now available
                            env.EFS_FILE_SYSTEM_ID = sh(returnStdout: true, script: 'terraform output -raw efs_file_system_id').trim()
                            env.EFS_ACCESS_POINT_ID = sh(returnStdout: true, script: 'terraform output -raw efs_access_point_id').trim()
                            env.EFS_SECURITY_GROUP_ID = sh(returnStdout: true, script: 'terraform output -raw efs_sg_id').trim()
                            // Correctly retrieving the private subnet ID where EFS is located
                            env.PRIVATE_SUBNET_ID = sh(returnStdout: true, script: 'terraform output -raw private_subnet_ids | jq -r ".[0]"').trim()
                        }
                    }
                }
            }
        }

        // stage('Populate EFS with LibreOffice') {
        //     agent {
        //         docker {
        //             image 'amazon/aws-cli:2.11.16'
        //             args '--user 0 --entrypoint=""'
        //         }
        //     }
        //     steps {
        //         script {
        //             withCredentials([
        //                 string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        //                 string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        //                 sshUserPrivateKey(credentialsId: 'ec2-ssh-key', keyFileVariable: 'SSH_KEY_FILE')
        //             ]) {
        //                 echo "Launching temporary EC2 instance in private subnet: ${env.PRIVATE_SUBNET_ID} with User Data script..."
                        
        //                 // User Data script to be executed on the EC2 instance at launch
        //                 def userDataScript = """
        //                     #!/bin/bash
        //                     set -ex
        //                     sudo yum update -y
        //                     sudo yum install -y amazon-efs-utils
        //                     echo "Waiting for EFS mount target..."
        //                     sleep 30
        //                     sudo mkdir -p /mnt/efs
        //                     sudo mount -t efs -o tls,accesspoint=${env.EFS_ACCESS_POINT_ID} ${env.EFS_FILE_SYSTEM_ID}.efs.${env.AWS_DEFAULT_REGION}.amazonaws.com:/ /mnt/efs
                            
        //                     # Download LibreOffice, install, and copy to EFS
        //                     wget "https://downloadarchive.documentfoundation.org/libreoffice/old/7.4.6.2/deb/x86_64/LibreOffice_7.4.6.2_Linux_x86-64_deb.tar.gz"
        //                     tar -zxvf LibreOffice_7.4.6.2_Linux_x86-64_deb.tar.gz
        //                     sudo yum install -y libreoffice
        //                     sudo cp -r /usr/lib64/libreoffice /mnt/efs/
                            
        //                     sudo umount /mnt/efs
        //                     echo "EFS population complete. Terminating instance..."
        //                     aws ec2 terminate-instances --instance-ids \$(curl -s http://169.254.169.254/latest/meta-data/instance-id) --region ${env.AWS_DEFAULT_REGION}
        //                 """

        //                 def run_instance_result = sh(
        //                     returnStdout: true,
        //                     script: """
        //                         aws ec2 run-instances \
        //                         --region ${env.AWS_DEFAULT_REGION} \
        //                         --image-id ${env.EC2_AMI} \
        //                         --instance-type t2.micro \
        //                         --key-name ${env.EC2_KEY_PAIR} \
        //                         --security-group-ids ${env.EFS_SECURITY_GROUP_ID} \
        //                         --subnet-id ${env.PRIVATE_SUBNET_ID} \
        //                         --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=jenkins-efs-populator}]' \
        //                         --user-data '${userDataScript}'
        //                     """
        //                 ).trim()
        //                 env.INSTANCE_ID = sh(returnStdout: true, script: "echo '${run_instance_result}' | jq -r '.Instances[0].InstanceId'").trim()
        //                 echo "Launched temporary EC2 instance ${env.INSTANCE_ID} with User Data. It will self-terminate after populating EFS."
        //             }
        //         }
        //     }
        // }

        // stage('Deploy Remainder with Terraform') {
        //     agent {
        //         docker {
        //             image 'hashicorp/terraform:1.5.7'
        //             args '--user 0 --entrypoint="" --dns 8.8.8.8'
        //         }
        //     }
        //     steps {
        //         script {
        //             withCredentials([
        //                 string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        //                 string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
        //             ]) {
        //                 unstash 'app-code'
        //                 unstash 'dependencies-layer'
                        
        //                 dir(env.TF_PATH) {
        //                     sh 'apk add --no-cache python3 py3-pip coreutils'
        //                     sh 'pip install awscli --no-cache-dir'

        //                     def fileHashApp = sh(returnStdout: true, script: "sha256sum ${APP_ZIP} | awk '{print \$1}'").trim()
        //                     def fileHashLayer = sh(returnStdout: true, script: "sha256sum ${LAYER_ZIP} | awk '{print \$1}'").trim()
                            
        //                     echo 'Deploying the remaining resources with Terraform...'
        //                     sh 'terraform init -upgrade'
        //                     sh """
        //                         terraform apply -auto-approve \
        //                         -var 's3_key_app=${APP_ZIP}' \
        //                         -var 'source_code_hash_app=${fileHashApp}' \
        //                         -var 's3_key_layer=${LAYER_ZIP}' \
        //                         -var 'source_code_hash_layer=${fileHashLayer}'
        //                     """
        //                 }
        //             }
        //         }
        //     }
        // }

        stage('Post-Deployment Info') {
            agent {
                docker {
                    image 'hashicorp/terraform:1.5.7'
                    args '--user 0 --entrypoint="" --dns 8.8.8.8'
                }
            }
            steps {
                script {
                    withCredentials([
                        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
                        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
                    ]) {
                        dir(env.TF_PATH) {
                            def apiGatewayUrl = sh(returnStdout: true, script: 'terraform output -raw api_gateway_url').trim()
                            echo "Deployment Complete! Your API Gateway URL: ${apiGatewayUrl}"
                        }
                    }
                }
            }
        }
    }

    post {
        always { echo 'Cleaning up...' }
        failure { echo 'Pipeline failed!' }
        success { echo 'Pipeline completed successfully!' }
    }
}
